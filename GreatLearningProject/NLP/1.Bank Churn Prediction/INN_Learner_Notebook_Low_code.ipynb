{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoO7ROnuht51"
      },
      "source": [
        "<center><font size=6> Bank Churn Prediction </font></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q__obHNhdHtV"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSyQJZSAaPA3"
      },
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJQ5k8umdJdN"
      },
      "source": [
        "Businesses like banks which provide service have to worry about problem of 'Customer Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on improvement of service, keeping in mind these priorities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s749lpTNaRkN"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbrLMQQ6dKQU"
      },
      "source": [
        "You as a Data scientist with the  bank need to  build a neural network based classifier that can determine whether a customer will leave the bank  or not in the next 6 months."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsb28swdaVAs"
      },
      "source": [
        "### Data Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mquomUwdMol"
      },
      "source": [
        "* CustomerId: Unique ID which is assigned to each customer\n",
        "\n",
        "* Surname: Last name of the customer\n",
        "\n",
        "* CreditScore: It defines the credit history of the customer.\n",
        "  \n",
        "* Geography: A customerâ€™s location\n",
        "   \n",
        "* Gender: It defines the Gender of the customer\n",
        "   \n",
        "* Age: Age of the customer\n",
        "    \n",
        "* Tenure: Number of years for which the customer has been with the bank\n",
        "\n",
        "* NumOfProducts: refers to the number of products that a customer has purchased through the bank.\n",
        "\n",
        "* Balance: Account balance\n",
        "\n",
        "* HasCrCard: It is a categorical variable which decides whether the customer has credit card or not.\n",
        "\n",
        "* EstimatedSalary: Estimated salary\n",
        "\n",
        "* IsActiveMember: Is is a categorical variable which decides whether the customer is active member of the bank or not ( Active member in the sense, using bank products regularly, making transactions etc )\n",
        "\n",
        "* Exited : whether or not the customer left the bank within six month. It can take two values\n",
        "    - 0 = No ( Customer did not leave the bank )\n",
        "    - 1 = Yes ( Customer left the bank )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyTYkHrRc0kz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHOIdlwcrqR"
      },
      "source": [
        "## **Please read the instructions carefully before starting the project.**\n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned.\n",
        "* Blanks '_______' are provided in the notebook that\n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space.\n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHHrSIl4c6Yn"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M3rUxqthe99Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\~andas\\\\_libs\\\\algos.cp310-win_amd64.pyd'\n",
            "Check the permissions.\n",
            "\n",
            "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "!pip install tensorflow==2.15.0 scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==2.0.3 imbalanced-learn==0.10.1 -q --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRowCcVjoIvv"
      },
      "source": [
        "**Note:** After running the above cell, please restart the notebook kernel/runtime (depending on whether you're using Jupyter Notebook or Google Colab) and then sequentially run all cells from the one below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfeZclzIHUNs"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Library to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# library to import to standardize the data\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# importing different functions to build models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# importing SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# importing metrics\n",
        "from sklearn.metrics import confusion_matrix,roc_curve,classification_report,recall_score\n",
        "\n",
        "import random\n",
        "\n",
        "# Library to avoid the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ubXtC8HUOA"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGZLJmZUdkPq"
      },
      "outputs": [],
      "source": [
        "# uncomment and run the following lines in case Colab is being used\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QJLp3P3HUOC"
      },
      "outputs": [],
      "source": [
        "ds = pd.read_csv(\"______\")    # complete the code to load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRxrJ2MHd_Sf"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaDNDpvjeBQU"
      },
      "source": [
        "### View the first and last 5 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCfASHJ8HUOS"
      },
      "outputs": [],
      "source": [
        "# let's view the first 5 rows of the data\n",
        "ds.'_______' ##  Complete the code to view top 5 rows of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImZogMSJeDe1"
      },
      "outputs": [],
      "source": [
        "# let's view the last 5 rows of the data\n",
        "ds.'_______' ##  Complete the code to view last 5 rows of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKrxKXZeH3o"
      },
      "source": [
        "### Understand the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfglAewPeIiS"
      },
      "outputs": [],
      "source": [
        "# Checking the number of rows and columns in the training data\n",
        "ds.'_______' ##  Complete the code to view dimensions of the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7eb88AYeRWk"
      },
      "source": [
        "### Check the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owLb0T9WHUO0"
      },
      "outputs": [],
      "source": [
        "ds.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJMOqyjUeXT9"
      },
      "source": [
        "### Checking the Statistical Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnW0F1yLeizR"
      },
      "outputs": [],
      "source": [
        "ds.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y23XCbZZhYVP"
      },
      "source": [
        "### Checking for Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6PMTkU5hY--"
      },
      "outputs": [],
      "source": [
        "# let's check for missing values in the data\n",
        "ds.'_______' ##  Complete the code to check missing entries in the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBNV_rtvhUQl"
      },
      "source": [
        "### Checking for unique values for each of the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9rwaHhLgpPG"
      },
      "outputs": [],
      "source": [
        "ds.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivF2RMo6HUOr"
      },
      "outputs": [],
      "source": [
        "#RowNumber , CustomerId and Surname are unique hence dropping it\n",
        "ds = ds.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W036jsgwRdVN"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSFkV8KJiZSv"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1Lxry70ibDw"
      },
      "outputs": [],
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to show the density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDMVw_AVic6c"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHFxrmIzkr7b"
      },
      "source": [
        "#### Observations on CreditScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4JoNzosjN-D"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(ds,'CreditScore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-p0ayX9kvQJ"
      },
      "source": [
        "#### Observations on Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUfIE-ndjN7b"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('__________________')          ## Complete the code to create histogram_boxplot for Age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrsE51KkwlT"
      },
      "source": [
        "#### Observations on Balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEM1HyJ2jN4h"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('__________________')          ## Complete the code to create histogram_boxplot for Balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztGKkX9Iky3M"
      },
      "source": [
        "#### Observations on Estimated Salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SenE1pZQjN2D"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('__________________')          ## Complete the code to create histogram_boxplot for Estimated Salary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnoUI00xk2B9"
      },
      "source": [
        "#### Observations on Exited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SAFx_W-jNzm"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(ds, \"Exited\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHmVTt5kk3zU"
      },
      "source": [
        "#### Observations on Geography"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKrzQJBPjNwr"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Geography"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHM8UMTUk58z"
      },
      "source": [
        "#### Observations on Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpfa_9vujNt2"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOVckLV7k77X"
      },
      "source": [
        "#### Observations on Tenure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_h-mVKYkOLq"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Tenure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rsLuf-_k9pE"
      },
      "source": [
        "#### Observations on Number of Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Aq7mK8kOI6"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Number of products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFTTZclZlAFR"
      },
      "source": [
        "#### Observations on Has Credit Card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7XlGlE1kbeB"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Has credit card"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PLoVR1vlCZ1"
      },
      "source": [
        "#### Observations on Is Active Member"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY1hA84okf9E"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('______________')               ## Complete the code to create labeled_barplot for Is active member"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlHTHF4glMxS"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_pKBXS9lLel"
      },
      "outputs": [],
      "source": [
        "# function to plot stacked bar chart\n",
        "\n",
        "\n",
        "def stacked_barplot(data, predictor, target):\n",
        "    \"\"\"\n",
        "    Print the category counts and plot a stacked bar chart\n",
        "\n",
        "    data: dataframe\n",
        "    predictor: independent variable\n",
        "    target: target variable\n",
        "    \"\"\"\n",
        "    count = data[predictor].nunique()\n",
        "    sorter = data[target].value_counts().index[-1]\n",
        "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    print(tab1)\n",
        "    print(\"-\" * 120)\n",
        "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n",
        "    plt.legend(\n",
        "        loc=\"lower left\",\n",
        "        frameon=False,\n",
        "    )\n",
        "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtHxkpQKllbh"
      },
      "source": [
        "#### Correlation plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LGAqynpFZDL"
      },
      "outputs": [],
      "source": [
        "# defining the list of numerical columns\n",
        "cols_list = [\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"EstimatedSalary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ_WDY2flnSO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "sns.heatmap(ds[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cFHFmnXowW3"
      },
      "source": [
        "#### Exited Vs Geography"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJEbKP88nDoT"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(ds, \"Geography\", \"Exited\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biEj4Pc9o3Cu"
      },
      "source": [
        "#### Exited Vs Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm49yxIVnDlB"
      },
      "outputs": [],
      "source": [
        "stacked_barplot('__________')                   ## Complete the code to plot stacked barplot for Exited and Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6AkVarto4yY"
      },
      "source": [
        "#### Exited Vs Has Credit Card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZduPs9prnDiS"
      },
      "outputs": [],
      "source": [
        "stacked_barplot('__________')                   ## Complete the code to plot stacked barplot for Exited and Has credit card"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abf32fRPo8J0"
      },
      "source": [
        "#### Exited Vs Is active member"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_kF4qwnnCkn"
      },
      "outputs": [],
      "source": [
        "stacked_barplot('__________')                   ## Complete the code to plot stacked barplot for Exited and Is active member"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Z0d0Wiqpu-"
      },
      "source": [
        "#### Exited Vs Credit Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coGfcr1spdXU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='CreditScore',x='Exited',data=ds)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSELHe5SqsN2"
      },
      "source": [
        "#### Exited Vs Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJjXjA16pdUA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='______',x='____',data=______)               ## Complete the code to plot the boxplot for Exited and Age\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIEluIj_qvpu"
      },
      "source": [
        "#### Exited Vs Tenure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwyd5XS4pdQ3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='______',x='____',data=______)               ## Complete the code to plot the boxplot for Exited and Tenure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCjF1MFJqxoz"
      },
      "source": [
        "#### Exited Vs Balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3psnDi6pcK4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='______',x='____',data=______)               ## Complete the code to plot the boxplot for Exited and Balance\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztZW3u5pqzXa"
      },
      "source": [
        "#### Exited Vs Number of Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBer-x0wqSw3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='______',x='____',data=______)               ## Complete the code to plot the boxplot for Exited and Number of products\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH0MzRYcq1tS"
      },
      "source": [
        "#### Exited Vs Estimated Salary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omsmYCNjqSt3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "sns.boxplot(y='______',x='____',data=______)               ## Complete the code to plot the boxplot for Exited and Estimated Salary\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUXPaUwZHUO8"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nEEjgwleiMv"
      },
      "source": [
        "### Dummy Variable Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTQtwT3KFy8S"
      },
      "outputs": [],
      "source": [
        "ds = pd.get_dummies(ds,columns=ds.select_dtypes(include=[\"object\"]).columns.tolist(),drop_first=True,dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgpx0xlSTlzN"
      },
      "source": [
        "### Train-validation-test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTb3JwlaHUO-"
      },
      "outputs": [],
      "source": [
        "X = ds.drop(['Exited'],axis=1) # Credit Score through Estimated Salary\n",
        "y = ds['Exited'] # Exited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YvyE1kXHUPl"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training and Testing set.\n",
        "\n",
        "X_large, X_test, y_large, y_test = train_test_split(X, y, test_size = _____, random_state = 42,stratify=y,shuffle = True) ## Complete the code to Split the X and y and obtain test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pBDBCW-c6Yx"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training and Testing set.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_large, y_large, test_size = _____, random_state = 42,stratify=y_large, shuffle = True) ## complete the code to Split X_large and y_large to obtain train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VzFfMQTI3vS"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3444KLnJCzK"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape, y_val.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlSyq5fNHUPp"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evREPGsuc6Yx"
      },
      "source": [
        "Since all the numerical values are on a different scale, so we will be scaling all the numerical values to bring them to the same scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7Gbl3Ac6Yx"
      },
      "outputs": [],
      "source": [
        "# creating an instance of the standard scaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train[cols_list] = sc.fit_transform(X_train[cols_list])\n",
        "X_val[cols_list] = sc.transform(X_val[_____])    ## Complete the code to specify the columns to normalize\n",
        "X_test[cols_list] = sc.transform(X_test[_____])    ## Complete the code to specify the columns to normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLQMVCywT87j"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDpHlsFT_QA"
      },
      "source": [
        "### Model Evaluation Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FayG94iciXVS"
      },
      "source": [
        "Write down the logic for choosing the metric that would be the best metric for this business scenario.\n",
        "\n",
        "-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7VmtBt7UP4i"
      },
      "source": [
        "**Let's create a function for plotting the confusion matrix**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovXvQoSbEfua"
      },
      "outputs": [],
      "source": [
        "def make_confusion_matrix(actual_targets, predicted_targets):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    actual_targets: actual target (dependent) variable values\n",
        "    predicted_targets: predicted target (dependent) variable values\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(actual_targets, predicted_targets)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPatWS-Ca9lu"
      },
      "source": [
        "Let's create two blank dataframes that will store the recall values for all the models we build."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3drHnx12DSf2"
      },
      "outputs": [],
      "source": [
        "train_metric_df = pd.DataFrame(columns=[\"recall\"])\n",
        "valid_metric_df = pd.DataFrame(columns=[\"recall\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "735HwSYiDSf1"
      },
      "source": [
        "### Neural Network with SGD Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScqNP3QjDSf3"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfcrQWAlDSf3"
      },
      "outputs": [],
      "source": [
        "#Initializing the neural network\n",
        "model_0 = Sequential()\n",
        "# Adding the input layer with 64 neurons and relu as activation function\n",
        "model_0.add(Dense(64, activation='relu', input_dim = X_train.shape[1]))\n",
        "# Complete the code to add a hidden layer (specify the # of neurons and the activation function)\n",
        "model_0.add(Dense(_____, activation='_____'))\n",
        "# Complete the code to add the output layer with the number of neurons required.\n",
        "model_0.add(Dense(_____, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9JbnUMScX6k"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use SGD as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____(0.001)\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1DP1Q1RcVY-"
      },
      "outputs": [],
      "source": [
        "## Complete the code to compile the model with binary cross entropy as loss function and recall as the metric.\n",
        "model_0.compile(loss='_____',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcERbmBsDSf4"
      },
      "outputs": [],
      "source": [
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdrozyCUDSf4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Fitting the ANN\n",
        "\n",
        "history_0 = model_0.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=______,    ## Complete the code to specify the batch size to use\n",
        "    validation_data=(X_val,y_val),\n",
        "    epochs=_____,    ## Complete the code to specify the number of epochs\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX__W6KQDSf5"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnIcofaEDSf5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_0.history['loss'])\n",
        "plt.plot(history_0.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggUulDUZDSf5"
      },
      "source": [
        "**Recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuKbK-KSDSf5"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_0.history['recall'])\n",
        "plt.plot(history_0.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d67w02x8dA4I"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using best as a threshold\n",
        "y_train_pred = model_0.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfKP-kCDdA4J"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using best as a threshold\n",
        "y_val_pred = model_0.predict(_____)    ## Complete the code to make prediction on the validation set\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57YBLOaOdA4J"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with SGD\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train, y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val, y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3dZPvbvdA4K"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-nK3s2xdA4K"
      },
      "outputs": [],
      "source": [
        "#lassification report\n",
        "cr = classification_report(y_train, y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb_9mvYFdA4K"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "cr=classification_report(_____, _____)    ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5q9TRfAdA4L"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi6FyHYQdA4M"
      },
      "outputs": [],
      "source": [
        "make_confusion_matrix(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo0sbIpHdA4M"
      },
      "outputs": [],
      "source": [
        "make_confusion_matrix(_____, _____)    ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygzPHkE_Anaw"
      },
      "source": [
        "## Model Performance Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcEiT7Vyc6Y0"
      },
      "source": [
        "### Neural Network with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du7tdC6fc6Y0"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36b7peUubI1q"
      },
      "outputs": [],
      "source": [
        "#Initializing the neural network\n",
        "model_1 = Sequential()\n",
        "#Complete the code to add a input layer (specify the # of neurons and activation function)\n",
        "model_1.add(Dense(___,activation='___',input_dim = X_train.shape[1]))\n",
        "#Complete the code to add a hidden layer (specify the # of neurons and activation function)\n",
        "model_1.add(Dense(___,activation='___'))\n",
        "#Complete the code to add a output layer with the required number of neurons and relu as activation function\n",
        "model_1.add(Dense(___, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTjQpDyCPrQU"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use Adam as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____()\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2WjF_d2Ppw8"
      },
      "outputs": [],
      "source": [
        "# Complete the code to compile the model with binary cross entropy as loss function and recall as the metric\n",
        "model_1.compile(loss='___',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVs_I0EubWk-"
      },
      "outputs": [],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j4im_XibZs2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Fitting the ANN\n",
        "history_1 = model_1.fit(\n",
        "    X_train,y_train,\n",
        "    batch_size=____, ## Complete the code to specify the batch size to use\n",
        "    validation_data=(X_val,y_val),\n",
        "    epochs=____, ## Complete the code to specify the number of epochs\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2opcOp0lrBYK"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZcVD0PdbjFJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHY5AVeCbzJg"
      },
      "source": [
        "**Recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw9wplWKoDlt"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_1.history['recall'])\n",
        "plt.plot(history_1.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fukpqiMgSwoH"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using 0.5 as the threshold\n",
        "y_train_pred = model_1.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE3vzi-LtwWa"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using 0.5 as the threshold\n",
        "y_val_pred = model_1.predict(X_val)\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnWQQMLLK_bS"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with Adam\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train,y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val,y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR7Z2n2sUw5m"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR3CrGxLTBBU"
      },
      "outputs": [],
      "source": [
        "#lassification report\n",
        "cr=classification_report(y_train,y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGW7G6s2c6Y2"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "cr=classification_report(____,____)  ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEYayn_Mb_fM"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU4lh3eLTHFf"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md-l0_EEcEHY"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(____,____)  ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ_FTNfU7ci"
      },
      "source": [
        "### Neural Network with Adam Optimizer and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hepmJoHGc6Y2"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXYhXhIec6Y2"
      },
      "outputs": [],
      "source": [
        "#Initializing the neural network\n",
        "model_2 = Sequential()\n",
        "#Adding the input layer with 32 neurons and relu as activation function\n",
        "model_2.add(Dense(32,activation='relu',input_dim = X_train.shape[1]))\n",
        "# Complete the code to add dropout with ratio of 0.2 or any suitable value.\n",
        "model_2.add(Dropout(___))\n",
        "# Complete the code to add a hidden layer (specify the # of neurons and the activation function)\n",
        "model_2.add(Dense(____,activation='____'))\n",
        "# Complete the code to add a hidden layer (specify the # of neurons and the activation function)\n",
        "model_2.add(Dense(____,activation='____'))\n",
        "# Complete the code to add dropout with ratio of 0.1 or any suitable value.\n",
        "model_2.add(Dropout(___))\n",
        "# Complete the code to add a hidden layer (specify the # of neurons and the activation function)\n",
        "model_2.add(Dense(____,activation='____'))\n",
        "# Complete the code to add the number of neurons required in the output layer.\n",
        "model_2.add(Dense(_____, activation = '____'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmAnz3zqXRws"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use Adam as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____()\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI_-pD8_XVDu"
      },
      "outputs": [],
      "source": [
        "## Complete the code to compile the model with binary cross entropy as loss function and recall as the metric.\n",
        "model_2.compile(loss='_____',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R33JPU3Wc6Y2"
      },
      "outputs": [],
      "source": [
        "# Summary of the model\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxFT1CkPc6Y2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Fitting the ANN with batch_size = 32 and 100 epochs\n",
        "history_2 = model_2.fit(\n",
        "    X_train,y_train,'\n",
        "    batch_size=____,  ##Complete the code to specify the batch size.\n",
        "    epochs=____, ##Complete the code to specify the # of epochs.\n",
        "    verbose=1,\n",
        "    validation_data=(X_val,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMg-yqR1Y7sD"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_snhdHfc6Y3"
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw9vGWmTc6Y3"
      },
      "source": [
        "From the above plot, we can observe that the train and validation curves are having smooth lines. Reducing the number of neurons and adding dropouts to the model worked, and the problem of overfitting was solved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qe2IAEJTmoa"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_2.history['recall'])\n",
        "plt.plot(history_2.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q08qHZXITw8l"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using best as a threshold\n",
        "y_train_pred = model_2.predict(X_train)\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StDmXPBRc6Y3"
      },
      "outputs": [],
      "source": [
        "#Predicting the results using 0.5 as the threshold.\n",
        "y_val_pred = model_2.predict(X_val)\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb7zqgcjLi-d"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with Adam & Dropout\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train,y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val,y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_EPhHQTZJLH"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8Y-4jCyT_Ra"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "cr=classification_report(y_train,y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsaMbvwnc6Y3"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "cr = classification_report(____,____) ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QVuR-atZMxh"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-OiI5i8UEMX"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoSge6xUc6Y3"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(____,____)  ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AFKraebbFFV"
      },
      "source": [
        "### Neural Network with Balanced Data (by applying SMOTE) and SGD Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76LzW0xQODsm"
      },
      "source": [
        "**Let's try to apply SMOTE to balance this dataset and then again apply hyperparamter tuning accordingly.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCHzSGvqQNY"
      },
      "outputs": [],
      "source": [
        "sm  = SMOTE(random_state=42)\n",
        "#Complete the code to fit SMOTE on the training data.\n",
        "X_train_smote, y_train_smote= sm.fit_resample(___,___)\n",
        "print('After UpSampling, the shape of train_X: {}'.format(X_train_smote.shape))\n",
        "print('After UpSampling, the shape of train_y: {} \\n'.format(y_train_smote.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBQRXPaQrfN1"
      },
      "source": [
        "Let's build a model with the balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBFMnlwsc6Y7"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCBmYTJ6rmoL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Initializing the model\n",
        "model_3 = Sequential()\n",
        "#Complete the code to add a input layer (specify the # of neurons and activation function)\n",
        "model_3.add(Dense(___,activation='____',input_dim = X_train_smote.shape[1]))\n",
        "#Complete the code to add a hidden layer (specify the # of neurons and activation function)\n",
        "model_3.add(Dense(16,activation='____'))\n",
        "#Complete the code to add a hidden layer (specify the # of neurons and activation function)\n",
        "model_3.add(Dense(___,activation='____'))\n",
        "# Complete the code to add the required number of neurons in the output layer with a sigmoid activation function.\n",
        "model_3.add(Dense(___, activation = '___'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKiOJpw-aUVb"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use SGD as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____(0.001)\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne3-sGZWaY1J"
      },
      "outputs": [],
      "source": [
        "# Complete the code to compile the model with binary cross entropy as loss function and recall as the metric\n",
        "model_3.compile(loss='___',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x98-PIwgiLN"
      },
      "outputs": [],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbKU-WUic6Y8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Fitting the ANN\n",
        "history_3 = model_3.fit(\n",
        "    X_train_smote, y_train_smote,\n",
        "    batch_size=____, ## Complete the code to specify the batch size to use\n",
        "    epochs=____, ## Complete the code to specify the number of epochs\n",
        "    verbose=1,\n",
        "    validation_data = (X_val,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiYwfXwHbSLs"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXyLsusWjgJi"
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_3.history['loss'])\n",
        "plt.plot(history_3.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbLB9raaVNaB"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_3.history['recall'])\n",
        "plt.plot(history_3.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se0zSvJMVTza"
      },
      "outputs": [],
      "source": [
        "y_train_pred = model_3.predict(X_train_smote)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09NXOv5usSVj"
      },
      "outputs": [],
      "source": [
        "y_val_pred = model_3.predict(X_val)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJJIpkzSLt35"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with SMOTE & SGD\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train_smote,y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val,y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR6hbqKvbWfj"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbDilz47VfCn"
      },
      "outputs": [],
      "source": [
        "cr=classification_report(y_train_smote,y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX3pGtousY5l"
      },
      "outputs": [],
      "source": [
        "cr=classification_report(____,____) ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZXBp6eWbZWG"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwuaTJCgVi4j"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_train_smote, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJemotBEsdUs"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "\n",
        "make_confusion_matrix(____,____) ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfhJCb0v16sR"
      },
      "source": [
        "### Neural Network with Balanced Data (by applying SMOTE) and Adam Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lILy8V7m16sa"
      },
      "source": [
        "Let's build a model with the balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-TsWvEL16sa"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF5XVyxO16sa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Initializing the model\n",
        "model_4 = Sequential()\n",
        "#Complete the code to add a input layer (specify the # of neurons and activation function)\n",
        "model_4.add(Dense(___,activation='___',input_dim = X_train_smote.shape[1]))\n",
        "#Complete the code to add a hidden layer (specify the # of neurons and activation function)\n",
        "model_4.add(Dense(____,activation='____'))\n",
        "#Complete the code to add a hidden layer (specify the # of neurons and activation function)\n",
        "model_4.add(Dense(___,activation='___'))\n",
        "# Complete the code to add the required number of neurons in the output layer and a suitable activation function.\n",
        "model_4.add(Dense(___, activation = '___'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AfTASP616sb"
      },
      "outputs": [],
      "source": [
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M7duKYpcjRT"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use Adam as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____()\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIvpeNr-clYi"
      },
      "outputs": [],
      "source": [
        "# Complete the code to compile the model with binary cross entropy as loss function and recall as the metric\n",
        "model_4.compile(loss='___',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2zYKiQ2c2JL"
      },
      "outputs": [],
      "source": [
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MNHx6Rj16sb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Fitting the ANN\n",
        "\n",
        "history_4 = model_4.fit(\n",
        "    X_train_smote,y_train_smote,\n",
        "    batch_size=____, ## Complete the code to specify the batch size to use\n",
        "    epochs=____,  ## Complete the code to specify the number of epochs\n",
        "    verbose=1,\n",
        "    validation_data = (X_val,y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-F5Y__S16sb"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVUOMwSu16sb"
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_4.history['loss'])\n",
        "plt.plot(history_4.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQm17WkxWIlB"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_4.history['recall'])\n",
        "plt.plot(history_4.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5chbJmFsWSr4"
      },
      "outputs": [],
      "source": [
        "y_train_pred = model_4.predict(X_train_smote)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgJa_ioD16sb"
      },
      "outputs": [],
      "source": [
        "y_val_pred = model_4.predict(X_val)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw0tDc1cL3B3"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with SMOTE & Adam\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train_smote,y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val,y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTeDxnT16sc"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZasyyABAWl_4"
      },
      "outputs": [],
      "source": [
        "cr=classification_report(y_train_smote,y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJS1OUFj16sc"
      },
      "outputs": [],
      "source": [
        "cr=classification_report(____,____) ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5P6fChl16sc"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARDvA5MYWrAD"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_train_smote, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_e_ouoi16sc"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(____,____)  ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v71_BRJ2Com"
      },
      "source": [
        "### Neural Network with Balanced Data (by applying SMOTE), Adam Optimizer, and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzoJ0gb82Coz"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpkkhRjy2Coz",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Initializing the model\n",
        "model_5 = Sequential()\n",
        "# Complete the code to add required # of neurons to the input layer with relu as activation function\n",
        "model_5.add(Dense(___,activation='___',input_dim = X_train_smote.shape[1]))\n",
        "#Complete the code to add dropout rate\n",
        "model_5.add(Dropout(___))\n",
        "# Complete the code to add required # neurons to the hidden layer with any activation function.\n",
        "model_5.add(Dense(___,activation='___'))\n",
        "# Complete the code to add dropout rate.\n",
        "model_5.add(Dropout(___))\n",
        "# Adding hidden layer with 8 neurons with relu as activation function\n",
        "model_5.add(Dense(8,activation='relu'))\n",
        "# Complete the code to add the required number of neurons in the output layer with a suitable activation function.\n",
        "model_5.add(Dense(___, activation = '___'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSaG0QkeSoH"
      },
      "outputs": [],
      "source": [
        "#Complete the code to use Adam as the optimizer.\n",
        "optimizer = tf.keras.optimizers.____()\n",
        "\n",
        "# uncomment one of the following lines to define the metric to be used\n",
        "# metric = 'accuracy'\n",
        "# metric = keras.metrics.Recall()\n",
        "# metric = keras.metrics.Precision()\n",
        "# metric = keras.metrics.F1Score()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOLsZmy2eW5A"
      },
      "outputs": [],
      "source": [
        "# Complete the code to compile the model with binary cross entropy as loss function and recall as the metric\n",
        "model_5.compile(loss='___',optimizer=optimizer,metrics=[metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taGBe-_72Co0"
      },
      "outputs": [],
      "source": [
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvJdZJ12Co0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history_5 = model_5.fit(\n",
        "    X_train_smote,y_train_smote,\n",
        "    batch_size=___, ## Complete the code to specify the batch size to use\n",
        "    epochs=____, ## Complete the code to specify the number of epochs\n",
        "    verbose=1,\n",
        "    validation_data = (X_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WePrnQXy2Co0"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn8E1cNr2Co0"
      },
      "outputs": [],
      "source": [
        "#Plotting Train Loss vs Validation Loss\n",
        "plt.plot(history_5.history['loss'])\n",
        "plt.plot(history_5.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Das0oy8GXB97"
      },
      "outputs": [],
      "source": [
        "#Plotting Train recall vs Validation recall\n",
        "plt.plot(history_5.history['recall'])\n",
        "plt.plot(history_5.history['val_recall'])\n",
        "plt.title('model recall')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ51zo1_XJKN"
      },
      "outputs": [],
      "source": [
        "y_train_pred = model_5.predict(X_train_smote)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_train_pred = (y_train_pred > 0.5)\n",
        "y_train_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PH6GWU2Co1"
      },
      "outputs": [],
      "source": [
        "y_val_pred = model_5.predict(X_val)\n",
        "#Predicting the results using 0.5 as the threshold\n",
        "y_val_pred = (y_val_pred > 0.5)\n",
        "y_val_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WCSbJ3LMFbD"
      },
      "outputs": [],
      "source": [
        "model_name = \"NN with SMOTE,Adam & Dropout\"\n",
        "\n",
        "train_metric_df.loc[model_name] = recall_score(y_train_smote,y_train_pred)\n",
        "valid_metric_df.loc[model_name] = recall_score(y_val,y_val_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKjSSJAW2Co1"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0lM4kouXSfh"
      },
      "outputs": [],
      "source": [
        "cr=classification_report(y_train_smote,y_train_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE6fhiYW2Co1"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "cr=classification_report(____,____)  ## Complete the code to check the model's performance on the validation set\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwsprLr32Co1"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh61OQ4bXWga"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_train_smote, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh66OtCH2Co1"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(____,____)  ## Complete the code to check the model's performance on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srfZVuMKc6Y_"
      },
      "source": [
        "## Model Performance Comparison and Final Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vhQsZT5MR_9"
      },
      "outputs": [],
      "source": [
        "print(\"Training performance comparison\")\n",
        "train_metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxPFe64OMZmq"
      },
      "outputs": [],
      "source": [
        "print(\"Validation set performance comparison\")\n",
        "valid_metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUmlwqKBXs-2"
      },
      "outputs": [],
      "source": [
        "train_metric_df - valid_metric_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IElL-J32Co1"
      },
      "outputs": [],
      "source": [
        "y_test_pred = _____.predict(X_test)    ## Complete the code to specify the best model\n",
        "y_test_pred = (y_test_pred > 0.5)\n",
        "print(y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL1decKP2Co2"
      },
      "outputs": [],
      "source": [
        "#lets print classification report\n",
        "cr=classification_report(y_test,y_test_pred)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehu4Ste92Co2"
      },
      "outputs": [],
      "source": [
        "#Calculating the confusion matrix\n",
        "make_confusion_matrix(y_test,y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1iHOqqOEmV"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouNNiEhUdhZL"
      },
      "source": [
        "*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R23W-K3CmM9"
      },
      "source": [
        "<font size=6 color='blue'>Power Ahead</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Q__obHNhdHtV",
        "WSyQJZSAaPA3",
        "s749lpTNaRkN",
        "Tsb28swdaVAs",
        "FHHrSIl4c6Yn",
        "z7ubXtC8HUOA",
        "eRxrJ2MHd_Sf",
        "QaDNDpvjeBQU",
        "RpKrxKXZeH3o",
        "b7eb88AYeRWk",
        "CJMOqyjUeXT9",
        "Y23XCbZZhYVP",
        "nSFkV8KJiZSv",
        "XHFxrmIzkr7b",
        "0-p0ayX9kvQJ",
        "OlHTHF4glMxS",
        "UtHxkpQKllbh",
        "3cFHFmnXowW3",
        "biEj4Pc9o3Cu",
        "e6AkVarto4yY",
        "abf32fRPo8J0",
        "J1Z0d0Wiqpu-",
        "bSELHe5SqsN2",
        "YIEluIj_qvpu",
        "bCjF1MFJqxoz",
        "ztZW3u5pqzXa",
        "DH0MzRYcq1tS",
        "CUXPaUwZHUO8",
        "1nEEjgwleiMv",
        "wgpx0xlSTlzN",
        "qlSyq5fNHUPp",
        "ZLQMVCywT87j",
        "SzDpHlsFT_QA",
        "735HwSYiDSf1",
        "ygzPHkE_Anaw",
        "EcEiT7Vyc6Y0",
        "xwJ_FTNfU7ci",
        "1AFKraebbFFV",
        "BfhJCb0v16sR",
        "8v71_BRJ2Com",
        "srfZVuMKc6Y_",
        "XE1iHOqqOEmV"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
